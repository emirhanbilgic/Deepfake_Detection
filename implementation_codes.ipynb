{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3qkgh6vg8zw"
      },
      "source": [
        "##MesoNet4 and MesoInception"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3Vq_Wqhygge"
      },
      "source": [
        "First, to download the dataset, the steps in the following link should be followed:\n",
        "https://github.com/ondyari/FaceForensics\n",
        "\n",
        "after achieving the downloading script, the following format should be followed to complete the download:\n",
        "\n",
        "\n",
        "```\n",
        "python3 download-FaceForensics.py\n",
        "    <output path>\n",
        "    -d <dataset type, e.g., Face2Face, original or all>\n",
        "    -c <compression quality, e.g., c23, raw or c40>\n",
        "    -t <file type, e.g., videos, masks or models>\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "which is in our case:\n",
        "\n",
        "`python3 script.py faceforensics -d all -c c40 -t videos --server EU2 `\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYlNNndLhNb_"
      },
      "source": [
        "After cloning https://github.com/HongguLiu/MesoNet-Pytorch, you will access all the required files. For example, the complete architecture implementation of MesoNet and MesoInception:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhUC5NlNhOQA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import torchvision\n",
        "\n",
        "class Meso4(nn.Module):\n",
        "\tdef __init__(self, num_classes=2):\n",
        "\t\tsuper(Meso4, self).__init__()\n",
        "\t\tself.num_classes = num_classes\n",
        "\t\tself.conv1 = nn.Conv2d(3, 8, 3, padding=1, bias=False)\n",
        "\t\tself.bn1 = nn.BatchNorm2d(8)\n",
        "\t\tself.relu = nn.ReLU(inplace=True)\n",
        "\t\tself.leakyrelu = nn.LeakyReLU(0.1)\n",
        "\n",
        "\t\tself.conv2 = nn.Conv2d(8, 8, 5, padding=2, bias=False)\n",
        "\t\tself.bn2 = nn.BatchNorm2d(16)\n",
        "\t\tself.conv3 = nn.Conv2d(8, 16, 5, padding=2, bias=False)\n",
        "\t\tself.conv4 = nn.Conv2d(16, 16, 5, padding=2, bias=False)\n",
        "\t\tself.maxpooling1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\t\tself.maxpooling2 = nn.MaxPool2d(kernel_size=(4, 4))\n",
        "\t\tself.dropout = nn.Dropout2d(0.5)\n",
        "\t\tself.fc1 = nn.Linear(16*8*8, 16)\n",
        "\t\tself.fc2 = nn.Linear(16, num_classes)\n",
        "\n",
        "\tdef forward(self, input):\n",
        "\t\tx = self.conv1(input)\n",
        "\t\tx = self.relu(x)\n",
        "\t\tx = self.bn1(x)\n",
        "\t\tx = self.maxpooling1(x)\n",
        "\n",
        "\t\tx = self.conv2(x)\n",
        "\t\tx = self.relu(x)\n",
        "\t\tx = self.bn1(x)\n",
        "\t\tx = self.maxpooling1(x)\n",
        "\n",
        "\t\tx = self.conv3(x)\n",
        "\t\tx = self.relu(x)\n",
        "\t\tx = self.bn2(x)\n",
        "\t\tx = self.maxpooling1(x)\n",
        "\n",
        "\t\tx = self.conv4(x)\n",
        "\t\tx = self.relu(x)\n",
        "\t\tx = self.bn2(x)\n",
        "\t\tx = self.maxpooling2(x)\n",
        "\n",
        "\t\tx = x.view(x.size(0), -1)\n",
        "\t\tx = self.dropout(x)\n",
        "\t\tx = self.fc1(x)\n",
        "\t\tx = self.leakyrelu(x)\n",
        "\t\tx = self.dropout(x)\n",
        "\t\tx = self.fc2(x)\n",
        "\n",
        "\t\treturn x\n",
        "\n",
        "\n",
        "class MesoInception4(nn.Module):\n",
        "\tdef __init__(self, num_classes=2):\n",
        "\t\tsuper(MesoInception4, self).__init__()\n",
        "\t\tself.num_classes = num_classes\n",
        "\t\tself.Incption1_conv1 = nn.Conv2d(3, 1, 1, padding=0, bias=False)\n",
        "\t\tself.Incption1_conv2_1 = nn.Conv2d(3, 4, 1, padding=0, bias=False)\n",
        "\t\tself.Incption1_conv2_2 = nn.Conv2d(4, 4, 3, padding=1, bias=False)\n",
        "\t\tself.Incption1_conv3_1 = nn.Conv2d(3, 4, 1, padding=0, bias=False)\n",
        "\t\tself.Incption1_conv3_2 = nn.Conv2d(4, 4, 3, padding=2, dilation=2, bias=False)\n",
        "\t\tself.Incption1_conv4_1 = nn.Conv2d(3, 2, 1, padding=0, bias=False)\n",
        "\t\tself.Incption1_conv4_2 = nn.Conv2d(2, 2, 3, padding=3, dilation=3, bias=False)\n",
        "\t\tself.Incption1_bn = nn.BatchNorm2d(11)\n",
        "\n",
        "\t\tself.Incption2_conv1 = nn.Conv2d(11, 2, 1, padding=0, bias=False)\n",
        "\t\tself.Incption2_conv2_1 = nn.Conv2d(11, 4, 1, padding=0, bias=False)\n",
        "\t\tself.Incption2_conv2_2 = nn.Conv2d(4, 4, 3, padding=1, bias=False)\n",
        "\t\tself.Incption2_conv3_1 = nn.Conv2d(11, 4, 1, padding=0, bias=False)\n",
        "\t\tself.Incption2_conv3_2 = nn.Conv2d(4, 4, 3, padding=2, dilation=2, bias=False)\n",
        "\t\tself.Incption2_conv4_1 = nn.Conv2d(11, 2, 1, padding=0, bias=False)\n",
        "\t\tself.Incption2_conv4_2 = nn.Conv2d(2, 2, 3, padding=3, dilation=3, bias=False)\n",
        "\t\tself.Incption2_bn = nn.BatchNorm2d(12)\n",
        "\n",
        "\t\tself.conv1 = nn.Conv2d(12, 16, 5, padding=2, bias=False)\n",
        "\t\tself.relu = nn.ReLU(inplace=True)\n",
        "\t\tself.leakyrelu = nn.LeakyReLU(0.1)\n",
        "\t\tself.bn1 = nn.BatchNorm2d(16)\n",
        "\t\tself.maxpooling1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "\t\tself.conv2 = nn.Conv2d(16, 16, 5, padding=2, bias=False)\n",
        "\t\tself.maxpooling2 = nn.MaxPool2d(kernel_size=(4, 4))\n",
        "\n",
        "\t\tself.dropout = nn.Dropout2d(0.5)\n",
        "\t\tself.fc1 = nn.Linear(16*8*8, 16)\n",
        "\t\tself.fc2 = nn.Linear(16, num_classes)\n",
        "\n",
        "\tdef InceptionLayer1(self, input):\n",
        "\t\tx1 = self.Incption1_conv1(input)\n",
        "\t\tx2 = self.Incption1_conv2_1(input)\n",
        "\t\tx2 = self.Incption1_conv2_2(x2)\n",
        "\t\tx3 = self.Incption1_conv3_1(input)\n",
        "\t\tx3 = self.Incption1_conv3_2(x3)\n",
        "\t\tx4 = self.Incption1_conv4_1(input)\n",
        "\t\tx4 = self.Incption1_conv4_2(x4)\n",
        "\t\ty = torch.cat((x1, x2, x3, x4), 1)\n",
        "\t\ty = self.Incption1_bn(y)\n",
        "\t\ty = self.maxpooling1(y)\n",
        "\n",
        "\t\treturn y\n",
        "\n",
        "\tdef InceptionLayer2(self, input):\n",
        "\t\tx1 = self.Incption2_conv1(input)\n",
        "\t\tx2 = self.Incption2_conv2_1(input)\n",
        "\t\tx2 = self.Incption2_conv2_2(x2)\n",
        "\t\tx3 = self.Incption2_conv3_1(input)\n",
        "\t\tx3 = self.Incption2_conv3_2(x3)\n",
        "\t\tx4 = self.Incption2_conv4_1(input)\n",
        "\t\tx4 = self.Incption2_conv4_2(x4)\n",
        "\t\ty = torch.cat((x1, x2, x3, x4), 1)\n",
        "\t\ty = self.Incption2_bn(y)\n",
        "\t\ty = self.maxpooling1(y)\n",
        "\n",
        "\t\treturn y\n",
        "\n",
        "\tdef forward(self, input):\n",
        "\t\tx = self.InceptionLayer1(input)\n",
        "\t\tx = self.InceptionLayer2(x)\n",
        "\n",
        "\t\tx = self.conv1(x)\n",
        "\t\tx = self.relu(x)\n",
        "\t\tx = self.bn1(x)\n",
        "\t\tx = self.maxpooling1(x)\n",
        "\n",
        "\t\tx = self.conv2(x)\n",
        "\t\tx = self.relu(x)\n",
        "\t\tx = self.bn1(x)\n",
        "\t\tx = self.maxpooling2(x)\n",
        "\n",
        "\t\tx = x.view(x.size(0), -1)\n",
        "\t\tx = self.dropout(x)\n",
        "\t\tx = self.fc1(x)\n",
        "\t\tx = self.leakyrelu(x)\n",
        "\t\tx = self.dropout(x)\n",
        "\t\tx = self.fc2(x)\n",
        "\n",
        "\t\treturn x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lmfazbOg8zw"
      },
      "source": [
        "Install the python packages with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_AnWK-lg8zx"
      },
      "outputs": [],
      "source": [
        "!python3 -m pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co7R4OFDhJAR"
      },
      "source": [
        "To train the MesoNet4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmptKCohxl32"
      },
      "outputs": [],
      "source": [
        "!python3 train_Meso.py -n 'Mesonet' -tp './data/train' -vp './data/val' -bz 64 -e 100 -mn 'meso4.pkl'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JipYu-KmhKUH"
      },
      "source": [
        "To train the MesoInceptionNet4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QO3R52yWxzy4"
      },
      "outputs": [],
      "source": [
        "!python3 train_MesoInception.py -n 'MesoInception' -tp './data/train' -vp './data/val' -bz 64 -e 100 -mn 'mesoinception.pkl'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIM-FpBvg8zx"
      },
      "source": [
        "To test the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvIQrIQVx5qM"
      },
      "outputs": [],
      "source": [
        "!python3 test.py -bz 64 -tp './data/test' -mp './Mesonet/best.pkl'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbmahaZ7yEsW"
      },
      "source": [
        "##Xception"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz5PhyrgypIp"
      },
      "source": [
        "After cloning https://github.com/i3p9/deepfake-detection-with-xception:\n",
        "\n",
        "Put FF++ dataset under the ./dataset.\n",
        "\n",
        "To do that, move the FaceForensics++ data to the appropriate paths:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTCZ9eBrcEQK"
      },
      "outputs": [],
      "source": [
        "!mv faceforensics/original_sequences/youtube/c23/videos/* /home/paperspace/deepfake-detection-with-xception/dataset/real\n",
        "!mv faceforensics/manipulated_sequences/Deepfakes/c23/videos* /home/paperspace/deepfake-detection-with-xception/dataset/fake"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gilkNiaRcJD9"
      },
      "source": [
        "Update the train_dateset.py file as the following and rename it to train_dataset.py."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0oLe4cacKkQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import argparse\n",
        "import matplotlib\n",
        "import imghdr\n",
        "import pickle as pkl\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.xception import Xception, preprocess_input\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Suppress TensorFlow warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "matplotlib.use('Agg')\n",
        "current_directory = os.path.dirname(os.path.abspath(__file__))\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('dataset_root')\n",
        "parser.add_argument('classes')\n",
        "parser.add_argument('result_root')\n",
        "parser.add_argument('--epochs_pre', type=int, default=10)\n",
        "parser.add_argument('--epochs_fine', type=int, default=30)\n",
        "parser.add_argument('--batch_size_pre', type=int, default=32)\n",
        "parser.add_argument('--batch_size_fine', type=int, default=16)\n",
        "parser.add_argument('--lr_pre', type=float, default=5e-3)\n",
        "parser.add_argument('--lr_fine', type=float, default=5e-4)\n",
        "parser.add_argument('--snapshot_period_pre', type=int, default=1)\n",
        "parser.add_argument('--snapshot_period_fine', type=int, default=1)\n",
        "parser.add_argument('--split', type=float, default=0.8)\n",
        "\n",
        "\n",
        "def generate_from_paths_and_labels(input_paths, labels, batch_size, input_size=(299, 299)):\n",
        "    num_samples = len(input_paths)\n",
        "    while 1:\n",
        "        perm = np.random.permutation(num_samples)\n",
        "        input_paths = input_paths[perm]\n",
        "        labels = labels[perm]\n",
        "        for i in range(0, num_samples, batch_size):\n",
        "            inputs = list(map(\n",
        "                lambda x: image.load_img(x, target_size=input_size),\n",
        "                input_paths[i:i+batch_size]\n",
        "            ))\n",
        "            inputs = np.array(list(map(\n",
        "                lambda x: image.img_to_array(x),\n",
        "                inputs\n",
        "            )))\n",
        "            inputs = preprocess_input(inputs)\n",
        "            yield (inputs, labels[i:i+batch_size])\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    print(\"Starting the script...\")\n",
        "\n",
        "    epochs = args.epochs_pre + args.epochs_fine\n",
        "    args.dataset_root = os.path.expanduser(args.dataset_root)\n",
        "    args.result_root = os.path.expanduser(args.result_root)\n",
        "    args.classes = os.path.expanduser(args.classes)\n",
        "\n",
        "    # load class names\n",
        "    print(\"Loading class names from:\", args.classes)\n",
        "    with open(args.classes, 'r') as f:\n",
        "        classes = f.readlines()\n",
        "        classes = list(map(lambda x: x.strip(), classes))\n",
        "    num_classes = len(classes)\n",
        "\n",
        "    # make input_paths and labels\n",
        "    input_paths, labels = [], []\n",
        "    for class_name in os.listdir(args.dataset_root):\n",
        "        class_root = os.path.join(args.dataset_root, class_name)\n",
        "        if not os.path.isdir(class_root):\n",
        "            continue\n",
        "        print(\"Processing class:\", class_name)\n",
        "        class_id = classes.index(class_name)\n",
        "        for path in os.listdir(class_root):\n",
        "            path = os.path.join(class_root, path)\n",
        "            if imghdr.what(path) is None:\n",
        "                # this is not an image file\n",
        "                continue\n",
        "            input_paths.append(path)\n",
        "            labels.append(class_id)\n",
        "\n",
        "    print(\"Converting labels to one-hot-vector format...\")\n",
        "    labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "    print(\"Converting input paths to numpy array...\")\n",
        "    input_paths = np.array(input_paths)\n",
        "\n",
        "    # shuffle dataset\n",
        "    print(\"Shuffling the dataset...\")\n",
        "    perm = np.random.permutation(len(input_paths))\n",
        "    labels = labels[perm]\n",
        "    input_paths = input_paths[perm]\n",
        "\n",
        "    # split dataset for training and validation\n",
        "    border = int(len(input_paths) * args.split)\n",
        "    train_labels = labels[:border]\n",
        "    val_labels = labels[border:]\n",
        "    train_input_paths = input_paths[:border]\n",
        "    val_input_paths = input_paths[border:]\n",
        "    print(\"Training on %d images and labels\" % (len(train_input_paths)))\n",
        "    print(\"Validation on %d images and labels\" % (len(val_input_paths)))\n",
        "\n",
        "    if os.path.exists(args.result_root) is False:\n",
        "        os.makedirs(args.result_root)\n",
        "\n",
        "    print(\"Building the model...\")\n",
        "    # Build a custom Xception from pre-trained Xception model\n",
        "    base_model = Xception(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=(299, 299, 3))\n",
        "\n",
        "    # create a custom top classifier\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.inputs, outputs=predictions)\n",
        "\n",
        "    # Train only the top classifier\n",
        "    # freeze the body layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # compile model\n",
        "    print(\"Compiling the model for pre-training...\")\n",
        "    model.compile(\n",
        "        loss=categorical_crossentropy,\n",
        "        optimizer=Adam(learning_rate=args.lr_pre),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # train\n",
        "    print(\"Starting pre-training...\")\n",
        "    hist_pre = model.fit(\n",
        "        generate_from_paths_and_labels(\n",
        "            input_paths=train_input_paths,\n",
        "            labels=train_labels,\n",
        "            batch_size=args.batch_size_pre\n",
        "        ),\n",
        "        steps_per_epoch=math.ceil(\n",
        "            len(train_input_paths) / args.batch_size_pre),\n",
        "        epochs=args.epochs_pre,\n",
        "        validation_data=generate_from_paths_and_labels(\n",
        "            input_paths=val_input_paths,\n",
        "            labels=val_labels,\n",
        "            batch_size=args.batch_size_pre\n",
        "        ),\n",
        "        validation_steps=math.ceil(\n",
        "            len(val_input_paths) / args.batch_size_pre),\n",
        "        verbose=1,\n",
        "        callbacks=[\n",
        "            ModelCheckpoint(\n",
        "                filepath=os.path.join(\n",
        "                    args.result_root,\n",
        "                    'model_pre_ep{epoch}_acc{accuracy:.3f}.keras'),\n",
        "                save_freq=args.snapshot_period_pre * len(train_input_paths) // args.batch_size_pre,\n",
        "            ),\n",
        "        ],\n",
        "    )\n",
        "    model.save(os.path.join(args.result_root, 'model_pre_final.keras'))\n",
        "\n",
        "    # Train the whole model\n",
        "    print(\"Starting fine-tuning...\")\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = True  # all layers are set as trainable\n",
        "\n",
        "    # recompile\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=args.lr_fine),\n",
        "        loss=categorical_crossentropy,\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "    # train\n",
        "    hist_fine = model.fit(\n",
        "        generate_from_paths_and_labels(\n",
        "            input_paths=train_input_paths,\n",
        "            labels=train_labels,\n",
        "            batch_size=args.batch_size_fine\n",
        "        ),\n",
        "        steps_per_epoch=math.ceil(\n",
        "            len(train_input_paths) / args.batch_size_fine),\n",
        "        epochs=args.epochs_fine,\n",
        "        validation_data=generate_from_paths_and_labels(\n",
        "            input_paths=val_input_paths,\n",
        "            labels=val_labels,\n",
        "            batch_size=args.batch_size_fine\n",
        "        ),\n",
        "        validation_steps=math.ceil(\n",
        "            len(val_input_paths) / args.batch_size_fine),\n",
        "        verbose=1,\n",
        "        callbacks=[\n",
        "            ModelCheckpoint(\n",
        "                filepath=os.path.join(\n",
        "                    args.result_root,\n",
        "                    'model_fine_ep{epoch}_acc{accuracy:.3f}.keras'),\n",
        "                save_freq=args.snapshot_period_fine * len(train_input_paths) // args.batch_size_fine,\n",
        "            ),\n",
        "        ],\n",
        "    )\n",
        "    model.save(os.path.join(args.result_root, 'model_fine_final.keras'))\n",
        "\n",
        "    # Create result graphs\n",
        "    print(\"Generating result graphs...\")\n",
        "    acc = hist_pre.history['accuracy']\n",
        "    val_acc = hist_pre.history['val_accuracy']\n",
        "    loss = hist_pre.history['loss']\n",
        "    val_loss = hist_pre.history['val_loss']\n",
        "    acc.extend(hist_fine.history['accuracy'])\n",
        "    val_acc.extend(hist_fine.history['val_accuracy'])\n",
        "    loss.extend(hist_fine.history['loss'])\n",
        "    val_loss.extend(hist_fine.history['val_loss'])\n",
        "\n",
        "    # save graph image\n",
        "    plt.plot(range(epochs), acc, marker='.', label='accuracy')\n",
        "    plt.plot(range(epochs), val_acc, marker='.', label='val_accuracy')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid()\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.savefig(os.path.join(args.result_root, 'accuracy.png'))\n",
        "    plt.clf()\n",
        "\n",
        "    plt.plot(range(epochs), loss, marker='.', label='loss')\n",
        "    plt.plot(range(epochs), val_loss, marker='.', label='val_loss')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid()\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.savefig(os.path.join(args.result_root, 'loss.png'))\n",
        "    plt.clf()\n",
        "\n",
        "    # save plot data\n",
        "    print(\"Saving plot data...\")\n",
        "    plot = {\n",
        "        'accuracy': acc,\n",
        "        'val_accuracy': val_acc,\n",
        "        'loss': loss,\n",
        "        'val_loss': val_loss,\n",
        "    }\n",
        "    with open(os.path.join(args.result_root, 'plot.dump'), 'wb') as f:\n",
        "        pkl.dump(plot, f)\n",
        "\n",
        "    print(\"Script completed successfully.\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args = parser.parse_args()\n",
        "    main(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqUpMdc9cNHj"
      },
      "source": [
        "Then, run the training script:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKjt2YLbzCm7"
      },
      "outputs": [],
      "source": [
        "!python3 train_dataset.py dataset dataset/classes.txt deepfake-detection-with-xception/results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVdTYa-W3HUE"
      },
      "source": [
        "##Face X-Ray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naq_Uruu3WFn"
      },
      "source": [
        "After cloning https://github.com/AlgoHunt/Face-Xray ,\n",
        "just run bi_online_generation.py file to generate the X-Rays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGiqyo3R3kZQ"
      },
      "outputs": [],
      "source": [
        "!python3 bi_online_generation.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFpq11wPg8zu"
      },
      "source": [
        "##Implicit Identity Leakage: The Stumbling Block to Improving Deepfake Detection Generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOJWU6CPg8zv"
      },
      "source": [
        "After cloning https://github.com/megvii-research/CADDM:\n",
        "\n",
        "Put FF++ dataset under the ./data.\n",
        "\n",
        "Download the landmark detector from https://github.com/codeniko/shape_predictor_81_face_landmarks and put it in the folder ./lib.\n",
        "\n",
        "Run the code to extract frames from FF++ videos and save them under the ./train_images or ./test_images based on the division in the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UIy9oifg8zv"
      },
      "outputs": [],
      "source": [
        "!python3 lib/extract_frames_ldm_ff++.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGF2ESSag8zw"
      },
      "source": [
        "Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkRX5o69g8zw"
      },
      "outputs": [],
      "source": [
        "!python3 test.py --cfg ./configs/caddm_test.cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg62L8J5g8zw"
      },
      "source": [
        "Training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VEd9Liig8zw"
      },
      "outputs": [],
      "source": [
        "!python3 train.py --cfg ./configs/caddm_train.cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VOZ606v6uvQ"
      },
      "source": [
        "###PS: For Cross-Dataset Testing of Each Method\n",
        "\n",
        "Download the Celeb-DF dataset using the steps in the link: https://github.com/yuezunli/celeb-deepfakeforensics"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
